{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from jamotools import Vectorizationer, rules\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the model on various phonological phenomena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first load the model\n",
    "# NOTE: load_model() loads a fully compiled model identical to the one saved using .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"pronunciation_prediction.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference DataFrame to ensure that the model wasn't trained on the entries it's being given for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>word_id</th>\n",
       "      <th>spelling</th>\n",
       "      <th>pronunciation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13943</td>\n",
       "      <td>역사학</td>\n",
       "      <td>역사학</td>\n",
       "      <td>역싸학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13943</td>\n",
       "      <td>역사학</td>\n",
       "      <td>역사학이</td>\n",
       "      <td>역싸하기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13943</td>\n",
       "      <td>역사학</td>\n",
       "      <td>역사학도</td>\n",
       "      <td>역싸학또</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13943</td>\n",
       "      <td>역사학</td>\n",
       "      <td>역사학만</td>\n",
       "      <td>역싸항만</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13957</td>\n",
       "      <td>시대적2</td>\n",
       "      <td>시대적</td>\n",
       "      <td>시대적</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id word_id spelling pronunciation\n",
       "0     13943     역사학      역사학           역싸학\n",
       "1     13943     역사학     역사학이          역싸하기\n",
       "2     13943     역사학     역사학도          역싸학또\n",
       "3     13943     역사학     역사학만          역싸항만\n",
       "4     13957    시대적2      시대적           시대적"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = pd.read_csv(\"reference_all.csv\", sep=\"\\t\")\n",
    "ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the spelling column is needed, and store as a set since sets (and dicts) are implemented as hash tables underneath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = set(ref.spelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the vectorizer for decoding predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = Vectorizationer(rule=rules.RULE_1, max_length=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for unvectorizing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = {v: k for k, v in vec.symbol_map.items()}\n",
    "\n",
    "def unvectorize_norm_pad(vector):\n",
    "    temp_list = [decoder[num] for num in vector if num != 0]\n",
    "    temp_string = \"\".join(temp_list)\n",
    "    return normalize(\"NFC\", temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for comparing items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_string = 23\n",
    "\n",
    "def validate_model(phenomena):\n",
    "    \n",
    "    print(\"  {:15} {:15} {:15}\".format(\"Spelling\", \"Pronunciation\", \"Predicted Pronunciation\"))\n",
    "    \n",
    "    correct = 0\n",
    "    skipped = 0\n",
    "    total = len(phenomena)\n",
    "    \n",
    "    for instance in phenomena:\n",
    "        spelling = instance[0]\n",
    "        pronunciation = instance[1]\n",
    "        \n",
    "        if spelling in training_set:\n",
    "            print()\n",
    "            print(f\"{spelling} was in the training set. skipping.\")\n",
    "            print()\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        spell_vec = vec.vectorize(spelling)\n",
    "        \n",
    "        zeros_to_pad = longest_string - len(spell_vec)\n",
    "        \n",
    "        spell_padded = np.pad(spell_vec, (0, zeros_to_pad), \"constant\")\n",
    "\n",
    "        spell_padded = spell_padded.reshape(1, spell_padded.shape[0])\n",
    "        \n",
    "        prediction = model.predict(spell_padded)[0].argmax(axis=1)\n",
    "        \n",
    "        predicted_pronunciation = unvectorize_norm_pad(prediction)\n",
    "        \n",
    "        image = \"☒\"\n",
    "        \n",
    "        if pronunciation == predicted_pronunciation:\n",
    "            correct += 1\n",
    "            image = \"☑\"\n",
    "        \n",
    "        justify = 16 + len(predicted_pronunciation) - len(pronunciation)*2\n",
    "        print(\"{} {:10} {:>5} {}\".format(image, spelling, pronunciation, predicted_pronunciation.rjust(justify)))\n",
    "        \n",
    "    print()\n",
    "    print(\"Accuracy: {:.2f}%\".format(100 * correct/(total-skipped)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the phenomena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resyllabification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"When a syllable-final consonant is followed without pause by a vowel in the following syllable, that consonant is carried over to the following syllable to function as its initial consonant in pronunciation. The following syllable may be a part of a suffix or another word. This linking of syllable-final consonant to following syllable in pronunciation is...resyllabification.\" Cho et al. (2009). Integrated Korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: additional phenomena tested are indicated via line comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resyllabification = [\n",
    "    [\"한글은\", \"한그른\"],\n",
    "    [\"읽어요\", \"일거요\"],\n",
    "    [\"책을\", \"채글\"],\n",
    "    [\"알았어요\", \"아라써요\"], \n",
    "    [\"질문이\", \"질무니\"],      \n",
    "    [\"있어요\", \"이써요\"],\n",
    "    [\"읽어\", \"일거\"],\n",
    "    [\"들으세요\", \"드르세요\"],\n",
    "    [\"맞았어요\", \"마자써요\"],\n",
    "    [\"앉으세요\", \"안즈세요\"],\n",
    "    [\"천만에요\", \"천마네요\"],\n",
    "    [\"책이\", \"채기\"],\n",
    "    [\"없어요\", \"업서요\"],\n",
    "    [\"백화점에\", \"배콰저메\"], # aspiration and ㅎ weakening\n",
    "    [\"갔어요\", \"가써요\"],\n",
    "    [\"옷을\", \"오슬\"],\n",
    "    [\"받았어요\", \"바다써요\"],\n",
    "    [\"꽃은\", \"꼬츤\"],\n",
    "    [\"잎이\", \"이피\"],\n",
    "    [\"같아요\", \"가타요\"],\n",
    "    [\"갔어\", \"가써\"],\n",
    "    [\"낮에\", \"나제\"],\n",
    "    [\"빛이\", \"비치\"],\n",
    "    [\"부엌에\", \"부어케\"],\n",
    "    [\"낚아요\", \"나까요\"],\n",
    "    [\"꽃이\", \"꼬치\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Spelling        Pronunciation   Predicted Pronunciation\n",
      "☒ 한글은          한그른           한글ᅳᅳᆫ\n",
      "☑ 읽어요          일거요           일거요\n",
      "☑ 책을            채글             채글\n",
      "☒ 알았어요        아라써요         아라어요\n",
      "☑ 질문이          질무니           질무니\n",
      "☒ 있어요          이써요           읻ᅥ요\n",
      "\n",
      "읽어 was in the training set. skipping.\n",
      "\n",
      "☑ 들으세요        드르세요         드르세요\n",
      "☒ 맞았어요        마자써요         마자꺼ᄋ\n",
      "☑ 앉으세요        안즈세요         안즈세요\n",
      "☒ 천만에요        천마네요         천다ᄂᄋ요\n",
      "\n",
      "책이 was in the training set. skipping.\n",
      "\n",
      "☒ 없어요          업서요           업:ᅥᄋ요\n",
      "☒ 백화점에        배콰저메         배콰점ᅦ\n",
      "☒ 갔어요          가써요           가더요\n",
      "☒ 옷을            오슬             온ᅳᆯ\n",
      "☒ 받았어요        바다써요         바다어요\n",
      "☑ 꽃은            꼬츤             꼬츤\n",
      "\n",
      "잎이 was in the training set. skipping.\n",
      "\n",
      "☑ 같아요          가타요           가타요\n",
      "☒ 갔어            가써             가서\n",
      "☒ 낮에            나제             나ᄌᄌ\n",
      "\n",
      "빛이 was in the training set. skipping.\n",
      "\n",
      "☒ 부엌에          부어케           부어커\n",
      "☑ 낚아요          나까요           나까요\n",
      "\n",
      "꽃이 was in the training set. skipping.\n",
      "\n",
      "\n",
      "Accuracy: 38.10%\n"
     ]
    }
   ],
   "source": [
    "validate_model(resyllabification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syllable-final closure (unrelease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"At the end of a word or before a consonant, all Korean consonants are pronounced with closure of the speech organs involved, that is, without releasing air. As a result, sound changes occur in consonants in word-final or pre-consonantal position. For example, 꽃은 'as for flowers' is pronounced without any change in ㅊ because the word 꽃 'flower' is immediately followed by the vowel-initial particle 은 'as for'. However, 꽃 'flower' and 꽃도 'flower also' are pronounced 꼳 and 꼳또 respectively. The change of ㅊ to ㄷ here happens because the speech organs (the tongue and the hard palate) responsible for the articulation of the word-final and pre-consonantal ㅊ are not released.\" \n",
    "\n",
    "Lips: ㅂ, ㅍ ==> ㅂ\n",
    "\n",
    "Gum ridge and hard palate: ㄷ, ㅌ, ㅅ, ㅆ, ㅈ, ㅊ ==> ㄷ\n",
    "\n",
    "Soft palate: ㄱ, ㅋ, ㄲ ==> ㄱ\n",
    "\n",
    "Cho et al. (2009). Integrated Korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrelease = [\n",
    "    [\"꽃도\", \"꼳또\"],\n",
    "    [\"잎과\", \"입꽈\"],\n",
    "    [\"옷도\", \"옫또\"],\n",
    "    [\"갔지\", \"갇찌\"],\n",
    "    [\"낮과\", \"낟꽈\"],\n",
    "    [\"빛조차\", \"빋쪼차\"],\n",
    "    [\"부엌바닥\", \"부억빠닥\"],\n",
    "    [\"낚다가\", \"낙따가\"],\n",
    "    [\"꽃씨\", \"꼳씨\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Spelling        Pronunciation   Predicted Pronunciation\n",
      "\n",
      "꽃도 was in the training set. skipping.\n",
      "\n",
      "☑ 잎과            입꽈             입꽈\n",
      "\n",
      "옷도 was in the training set. skipping.\n",
      "\n",
      "☑ 갔지            갇찌             갇찌\n",
      "☑ 낮과            낟꽈             낟꽈\n",
      "☒ 빛조차          빋쪼차           빋쪼자\n",
      "☑ 부엌바닥        부억빠닥         부억빠닥\n",
      "☑ 낚다가          낙따가           낙따가\n",
      "\n",
      "꽃씨 was in the training set. skipping.\n",
      "\n",
      "\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "validate_model(unrelease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nasal assimilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"All plosive and fricative consonants become the corresponding nasal consonants before a nasal consonant (ㅁ, ㄴ). Notice that even ㅎ is included in the change.\"\n",
    "\n",
    "ㅂ, ㅍ ==> ㅁ\n",
    "\n",
    "ㄷ, ㅌ, ㅅ, ㅆ, ㅈ, ㅊ, ㅎ ==> ㄴ\n",
    "\n",
    "ㄱ, ㅋ, ㄲ ==> ㅇ\n",
    "\n",
    "Cho et al. (2009). Integrated Korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasal_assimilation = [\n",
    "    [\"입만\", \"임만\"],\n",
    "    [\"앞문\", \"암문\"],\n",
    "    [\"받는다\", \"반는다\"],\n",
    "    [\"끝나다\", \"끈나다\"],\n",
    "    [\"몇년\", \"면년\"],\n",
    "    [\"있는데\", \"인는데\"],\n",
    "    [\"일학년\", \"일항년\"],\n",
    "    [\"낳는다\", \"난는다\"],\n",
    "    [\"모르겠습니다\", \"모르겓씀니다\"], # unrelease\n",
    "    [\"한국말로\", \"한궁말로\"],\n",
    "    [\"합니까\", \"함니까\"],\n",
    "    [\"끝내겠습니다\", \"끈내겓씀니다\"]  # unrelease\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Spelling        Pronunciation   Predicted Pronunciation\n",
      "\n",
      "입만 was in the training set. skipping.\n",
      "\n",
      "\n",
      "앞문 was in the training set. skipping.\n",
      "\n",
      "☒ 받는다          반는다           반든다\n",
      "\n",
      "끝나다 was in the training set. skipping.\n",
      "\n",
      "☑ 몇년            면년             면년\n",
      "☑ 있는데          인는데           인는데\n",
      "☑ 일학년          일항년           일항년\n",
      "☑ 낳는다          난는다           난는다\n",
      "☒ 모르겠습니다     모르겓씀니다     모르겓쓰니다\n",
      "☒ 한국말로        한궁말로         한:궁망로\n",
      "☑ 합니까          함니까           함니까\n",
      "☒ 끝내겠습니다     끈내겓씀니다     끔내걷씀니다\n",
      "\n",
      "Accuracy: 55.56%\n"
     ]
    }
   ],
   "source": [
    "validate_model(nasal_assimilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
